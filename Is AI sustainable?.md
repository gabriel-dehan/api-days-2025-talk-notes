---
created: 2025-12-11T00:13
updated: 2025-12-11T16:52
---
### The Planetary Boundaries Framework

Contrary to the belief that AI is so powerful that what you can do with it is only limited by imagination, it is, in fact, physically limited by the Earth's finite capacity to provide resources and regenerate.

![[images/Gemini_Generated_Image_9o35c39o35c39o35.png]]

The physical infrastructure required for Generative AI - datacenters construction, energy consumption, water for cooling, and hardware manufacturing—directly impacts these boundaries.

The [scientific consensus on planetary health](https://www.stockholmresilience.org/research/planetary-boundaries.html) has worsened at an accelerating pace.
- **2009:** Scientists focused on 7 boundaries, and humanity had already overshot **3**.
- **2015:** **4** boundaries were considered crossed.
- **2023:** We now recognize 9 distinct boundaries, and we have breached **6** of them into the high-risk zone.
- **2025:** a **7th** boundary was crossed in 2025 with freshwater usage spiking.


> [!NOTE] If it were a human
> if Earth were a human patient, this progression would be terrifying. Breaking these boundaries is equivalent to a human developing a 40°C (104°F) fever, followed by heart complications, and then experiencing multiple organ failure.
>
> The critical difference is that when a human gets this sick, they go to a doctor. **There is no doctor for the Earth.** The current trajectory, fueled by energy-intensive technologies like Gen AI, is pushing the planet into an unsustainable state.

## The Real Environmental Impact: Biodiversity

The lifecycle of AI, from manufacturing to operation, directly impacts three specific planetary boundaries—Land System Change, Freshwater Use, and Climate Change—which in turn contribute to the collapse of biodiversity.

![[images/Gemini_Generated_Image_z7ahabz7ahabz7ah.png]]

Since the 70s, there has been a frightening 70% Biodiversity collapse:

![[images/Gemini_Generated_Image_z7ahabz7ahabz7ah (1).png]]
Source: [Our world in data](https://ourworldindata.org/biodiversity)

![[images/Gemini_Generated_Image_z7ahabz7ahabz7ah (2).png]]
Source: [Our world in data](https://ourworldindata.org/co2-and-greenhouse-gas-emissions)

## The Human Cost in Developing Countries

While we often imagine AI as an abstract, ethereal "cloud," its physical footprint is devastatingly real and _AI can be a curse for Global South people._ The intense demand for computational power drives a hardware manufacturing supply chain that relies on aggressive resource extraction.

This is most visible in the **Democratic Republic of Congo (DRC)**, a primary source for the copper and cobalt needed in the AI race. As reported by [David Maenda Kithoko](https://reporterre.net/Terres-detruites-sang-verse-cet-exile-denonce-les-ravages-de-l-extractivisme-au-Congo), this extraction comes at a horrific human cost, fuelled by child labor and armed conflict where rape is systematically used as a weapon of war.

The human exploitation extends beyond the mines. Even the "intelligence" of the models relies on a vast, invisible workforce. As [Antonio Casilli](youtube.com/watch?v=z_J_RNXaxbU) outlines, there is a massive market for "Ghost Work", often performed by low-paid data workers in Africa who painstakingly label the data required to train these systems.

## Downstream Impacts

If "upstream" represents the physical and human supply chain required to _create_ the AI, "downstream" refers to the societal and psychological consequences of _using_ it.
Once deployed, AI begins to fundamentally alter human behavior, the way we perceive truth, our political stability, and the professional lanscape.

#### 1. The Erosion of Truth (Deepfakes & Nihilism)

The immediate downstream danger is the proliferation of deepfakes, such as the AI-generated images of a Donald Trump arrest. However, the true threat isn't just that people might believe a specific lie; it is that the sheer volume of fabrication exhausts our collective ability to verify anything at all.

This echoes the warning of philosopher Hannah Arendt in 1958, who argued that constant lying is not done to convince people of a falsehood, but to ensure that _"no one believes anything anymore."_ When a society reaches this state of exhaustion—unable to distinguish fact from fiction or right from wrong—it loses its political agency, paving the way for totalitarianism.

> _What makes it possible for a totalitarian or any other dictatorship to rule is that people are not informed; how can you have an opinion if you are not informed?
> **If everybody always lies to you, the consequence is not that you believe the lies, but rather that nobody believes anything any longer._**
> [...]
> _And a people that no longer can believe anything cannot make up its mind._ _And with such a people you can then do what you please._
>
> - *Hannah Arendt*

#### 2. The Erosion of Skill (The New Proletariat)

The second major downstream impact is the "externalization" of our knowledge into machines. We are increasingly offloading our mental capabilities like thinking, writing or coding to AI.

Philosopher Bernard Stiegler *(1952-2020)* viewed this as a process of "proletarianization."

> *The proletariat is those who lost their knowledge because their knowledge is externalized in machines*.
>
> - *Bernard Stiegler*

Historically, this term described blue-collar workers who lost agency over their craft. Stiegler argues this is now happening to the **white-collar class**.

When professionals rely on AI to perform their core tasks, they cease to "own" their knowledge; it becomes externalized in the machine. Over time, this reliance leads to a loss of deep skill and "know-how." The result is a shift in class dynamics: formerly skilled professionals risk becoming "less trained" and dependent—effectively transitioning into a new proletariat that serves the machines which now hold the actual knowledge, and their masters.

#### 3. Reproducing Human Bias (Algorithmic Discrimination)

We need to challenge the assumption that machines are neutral. In reality, AI models act as mirrors that reflect—and often amplify—the historical prejudices contained in their training data. Because they "learn" from billions of human artifacts, they inevitably reproduce human biases, but with a veneer of mathematical objectivity that makes them harder to question.

This is strikingly illustrated by the computer vision example shown in the image below. When an image of a **light-skinned individual** holding a tool is processed, the system correctly identifies the object as a **"Tool"** (60% confidence). However, when the exact same tool is held by a **dark-skinned individual**, the system misidentifies the object as a **"Gun"** (61% confidence).

![](https://algorithmwatch.org/en/wp-content/uploads/2020/04/googlevision.png)

This is not merely a technical glitch; it is the automation of systemic racism. If such a system were deployed in real-world "downstream" scenarios—such as automated policing or security surveillance—it would disproportionately flag innocent people of color as threats while letting others pass.
*The danger here is that subjective racial profiling becomes embedded in the code, allowing discrimination to scale at the speed of software.*

## What can we do?

### What do we choose to do with our electricity?

Electricity is not an infinite resource; its generation has an immense environmental impact. Therefore, we must be discerning about its use, directing it toward critical societal needs rather than blindly funneling it into the exponential growth of AI infrastructure.

After a decade where data center energy consumption was relatively flat, we are now entering a period of massive scale-up. The graph below shows that under a "high adoption" scenario for AI, electricity consumption for data centers could increase **9.3 times** from 2023 levels by 2050, reaching a staggering 3,500 TWh.

![[images/Gemini_Generated_Image_i1duagi1duagi1du.png]]

The argument is clear: we cannot afford to let this massive consumption go unchecked. We must make active, conscious choices about where we allocate our limited energy resources.

### Using AI responsibly

If we acknowledge that computing power is a finite resource with a tangible environmental cost, we must adopt a framework of "Digital Sobriety." This means moving away from a one-size-fits-all approach where massive Generative AI models are applied to every problem.

Instead, we should visualize an **Energy Label for AI**, similar to how we rate household appliances, to weigh the energy cost against the societal value of the use case.

![[images/Gemini_Generated_Image_3q8mfy3q8mfy3q8m.png]]
We must stop conflating all AI with power-hungry Large Language Models (LLMs), which are effectively "Class Z" in energy efficiency.

For many tasks, we don't need a model that "understands" language; we simply need to process data. We should prioritize **discriminative AI** and efficient "Class A" algorithms like **Linear Regression**, **Random Forests**, or **Bernoulli Naive Bayes**. Using a Neural Network when a Decision Tree suffices is an ecological error.

**We must align the _cost_ of the compute with the _criticality_ of the task:**
Using AI to summarize emails or draft invites is a gross misuse of energy. These tasks belong to human cognition or simple scripts.
We should reserve our heavy computational firepower for **Individual Health** and **Large-scale Human Safety**, such as medical research or climate modeling.

### Use Alternative Hardwares

The current paradigm of throwing more GPUs at the problem is hitting diminishing returns. We need to explore hardware avenues that prioritize efficiency and longevity over raw speed.
#### Smaller Models and Older Hardware

The industry pushes a narrative that AI requires the latest, most expensive hardware and that inference needs datacenters to run. This drives a cycle of planned obsolescence that fills landfills with "outdated" devices. However, efficient software design can break this cycle.

We are seeing the rise of **Small Language Models (SLMs)** capable of running on legacy hardware. For example, optimized versions of Llama 2 have been successfully run on a **Pentium II**, a processor from the late 90s. By optimizing software to run on less powerful machines and sustainable devices like the **Fairphone**, we can drastically reduce e-waste and avoid using massive datacenters to ask simple questions like "What can I cook tonight with the ingredients I have in my fridge".
#### Analog and Biological Computing

We are also approaching the physical limits of digital silicon. To break the energy efficiency wall, researchers are looking back at **Analog Computing**.

Startups like **Sageance** are developing analog AI chips that process information using continuous signals (like light or voltage) rather than binary 0s and 1s. This approach mimics the physics of the real world, bypassing the energy-intensive data movement of traditional GPUs.

Even more radical is the push toward **Biological Computing**. Current research explores creating "wetware" machines using actual biological neurons. While still in its infancy, the potential is obvious when we look at the ultimate efficient machine: the human brain:
The Brain consumes ~20 Watts while LLM Training Cluster consumes MegaWatts. Nature has already solved the efficiency problem; our challenge is to replicate it.

### Evolving as a Society

Technological fixes—whether analog chips, smaller models, or energy labels—are necessary, but they are ultimately band-aids on a gaping wound.

The uncomfortable truth is that we cannot solve a problem created by infinite growth with _more_ growth. As Tristan Nitot noted, the frustration among climate advocates is palpable: _"I've been talking about climate change for years and nobody gives a shit. People care as a group, but not individually."_

This apathy is a symptom of a larger structure. The race to overconsumption, where we burn terawatts of energy to generate trivial images or marketing copy, is not an accident; it is a feature of the economic system.

Ultimately, the only true answer to the crisis of planetary boundaries is not just better AI, but a fundamental restructuring of our priorities. If the engine of our economy—**Capitalism**—requires the destruction of the Earth's regenerative capacity to function, then the sustainability of AI is inextricably linked to the question: **Can we afford to keep the system that built it?**
